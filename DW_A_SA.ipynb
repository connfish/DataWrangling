{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "60b3d9e3",
   "metadata": {},
   "source": [
    "# Data Wrangling using Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dea1e54",
   "metadata": {},
   "source": [
    "## Dataset Description: Student Assessment Questionnaires\n",
    "\n",
    "The dataset `assessment_generated.csv` contains information derived from student assessment questionnaires.\n",
    "\n",
    "Each record represents an individual student's response and includes demographic, academic, and self-assessment information. The dataset comprises the following attributes:\n",
    "\n",
    "- **`timestamp`**  \n",
    "  The date and time when the assessment was submitted, formatted as `yyyy-mm-dd hh:mm:ss timezone`.\n",
    "\n",
    "- **`netid`**  \n",
    "  The encoded NetID of the student. Valid NetIDs must have a string length between 8 and 14 characters (inclusive). Entries falling outside this range are considered invalid.\n",
    "\n",
    "- **`ruid`**  \n",
    "  The encoded RUID of the student. A valid RUID is expected to contain exactly 18 characters. Any deviation from this length is considered invalid.\n",
    "\n",
    "- **`section`**  \n",
    "  The course section number as reported by the student. This field may contain inaccuracies, as some students provided incorrect section information.\n",
    "\n",
    "- **`role`**  \n",
    "  The academic standing of the student. Possible values include:\n",
    "  - `Freshman`\n",
    "  - `Sophomore`\n",
    "  - `Junior`\n",
    "  - `Senior`\n",
    "  - `Graduate`\n",
    "  - `Other`\n",
    "\n",
    "- **`major`**  \n",
    "  The declared major of the student. Accepted categories are:\n",
    "  - `Computer Science`\n",
    "  - `Electrical and Computer Engineering`\n",
    "  - `Mathematics`\n",
    "  - `Other`\n",
    "\n",
    "- **Skill Proficiency Columns**  \n",
    "  The following columns record students’ self-assessed proficiency levels in specific skills, rated on scales ranging from 0 up to a multiple of 5 (depending on the number of questions per topic). Missing values are present in some entries.\n",
    "\n",
    "  - `data_structures`  \n",
    "  - `calculus_and_linear_algebra`  \n",
    "  - `probability_and_statistics`  \n",
    "  - `data_visualization`  \n",
    "  - `python_libraries`  \n",
    "  - `shell_scripting`  \n",
    "  - `sql`  \n",
    "  - `python_scripting`  \n",
    "  - `jupyter_notebook`  \n",
    "  - `regression`  \n",
    "  - `programming_languages`  \n",
    "  - `algorithms`  \n",
    "  - `complexity_measures`  \n",
    "  - `visualization_tools`  \n",
    "  - `massive_data_processing`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "746c5ff5",
   "metadata": {},
   "source": [
    "## Tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4ceaa86",
   "metadata": {},
   "source": [
    "- Import Data\n",
    "  - Load assessment_generated.xlsx as a DataFrame named student_assessment_xlsx.\n",
    "- Verify NetIDs\n",
    "  - Ensure that student_assessment_xlsx contains the same set of netids as student_assessment.\n",
    "- Analyze RUID Lengths\n",
    "  - Display the frequency of each ruid length.\n",
    "  - Display records where ruid length exceeds 20 characters.\n",
    "- Compute Total Score\n",
    "  - Create a new column total_score as the sum of all skill proficiency columns.\n",
    "  - Sort records by total_score in descending order.\n",
    "- Group Statistics by Section\n",
    "  - Group students by section and compute the mean, median, and standard deviation for each skill proficiency column.\n",
    "- Pivot Table by Role and Section\n",
    "  - Create a pivot table where:\n",
    "    - Rows correspond to role\n",
    "    - Columns correspond to section numbers\n",
    "    - Entries contain the average total_score\n",
    "- Format Timestamp\n",
    "  - Convert timestamp values to the EST timezone instead of UTC.\n",
    "- Normalize Skill Proficiency\n",
    "  - For each proficiency column, apply z-score normalization rather than min-max scaling.\n",
    "- Handle Missing Values\n",
    "  - Fill missing values in each skill proficiency column with the column mean.\n",
    "- Remove Duplicate Records\n",
    "  - Drop duplicates while keeping only the record with the highest total_score.\n",
    "- Resolve Swapped IDs\n",
    "  - Identify records where students may have swapped netid and ruid. (Hint: netid should be shorter than ruid.)\n",
    "- For records swapped netid and ruid, attempt a join using:\n",
    "  - student_assessment.ruid = student_list.netid\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be7a8fd9",
   "metadata": {},
   "source": [
    "### Setup Code (Please run this first to set up the environment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e67af9c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e27d9dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    skill_columns = [\n",
    "        'data_structures', 'calculus_and_linear_algebra', 'probability_and_statistics',\n",
    "        'data_visualization', 'python_libraries', 'shell_scripting', 'sql',\n",
    "        'python_scripting', 'jupyter_notebook', 'regression', 'programming_languages',\n",
    "        'algorithms', 'complexity_measures', 'visualization_tools', 'massive_data_processing'\n",
    "    ]\n",
    "\n",
    "    CSV_PATH = 'assessment_generated.csv'\n",
    "    # load csv file to a Pandas dataframe named student_assessments\n",
    "    student_assessments_csv = pd.read_csv(CSV_PATH)\n",
    "    display(student_assessments_csv)\n",
    "\n",
    "    STUDENT_LIST_PATH = 'student_list_generated.csv'\n",
    "    student_list_df = pd.read_csv(STUDENT_LIST_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d95541d0",
   "metadata": {},
   "source": [
    "### Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd7e186b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_data(path):\n",
    "    \"\"\"\n",
    "    Load assessment_generated.xlsx as a DataFrame \n",
    "    IN: path, str, path to the file\n",
    "    OUT: student_assessment_xlsx, pd.DataFrame\n",
    "    \"\"\"\n",
    "    # Your_Code_Here\n",
    "    return student_assessment_xlsx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e63a42aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    XLSX_PATH = 'assessment_generated.xlsx'\n",
    "    # load xlsx file to a Pandas dataframe named student_assessments\n",
    "    student_assessments_xlsx = import_data(XLSX_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f379fb71",
   "metadata": {},
   "source": [
    "### Verify NetIDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee4af63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_netids(df_csv, df_xlsx):\n",
    "    \"\"\"\n",
    "    Verify that the NetIDs in the CSV and XLSX files match\n",
    "    IN: df_csv, pd.DataFrame, dataframe from CSV file\n",
    "        df_xlsx, pd.DataFrame, dataframe from XLSX file\n",
    "    OUT: flag, bool, True if NetIDs match, False otherwise\n",
    "    \"\"\"\n",
    "    # Your_Code_Here\n",
    "    return flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ef6618",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    netid_same_flag = verify_netids(student_assessments_csv, student_assessments_xlsx)\n",
    "    print(f\"NetIDs match: {netid_same_flag}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bcc2db1",
   "metadata": {},
   "source": [
    "### Analyze RUID Lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6015bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ruid_length_freq(df):\n",
    "    \"\"\"\n",
    "    Get the frequency of RUID lengths in the dataframe\n",
    "    IN: df, pd.DataFrame, dataframe containing RUIDs\n",
    "    OUT: ruid_length_freq, dict, dictionary with RUID lengths as keys and their frequencies as values\n",
    "    \"\"\"\n",
    "    # Your_Code_Here\n",
    "    return ruid_length_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36544c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    ruid_length_freq = get_ruid_length_freq(student_assessments_xlsx)\n",
    "    for length, freq in sorted(ruid_length_freq.items()):\n",
    "        print(f\"RUID Length: {length:<2}, Frequency: {freq:<3}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95188d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ruid_length_outliers(df):\n",
    "    \"\"\"\n",
    "    Identify RUIDs with lengths that are > 20 characters\n",
    "    IN: df, pd.DataFrame, dataframe containing RUIDs\n",
    "    OUT: outliers, pd.DataFrame, dataframe containing outlier RUIDs\n",
    "    \"\"\"\n",
    "    # Your_Code_Here\n",
    "    return outliers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b1f8f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    outliers = get_ruid_length_outliers(student_assessments_xlsx)\n",
    "    display(outliers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab75698c",
   "metadata": {},
   "source": [
    "### Compute Total Score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a781eb",
   "metadata": {},
   "source": [
    "Note: Skip `nan` entries when computing sum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3c21861",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_total_score(df, skill_columns):\n",
    "    \"\"\"\n",
    "    Compute the total score for each student\n",
    "    IN: df, pd.DataFrame, dataframe containing student assessments\n",
    "    IN: skill_columns, list of str, list of columns to sum for total score\n",
    "    OUT: df, pd.DataFrame, dataframe with total_score column\n",
    "    \"\"\"\n",
    "    # Your_Code_Here\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8c76538",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_by_total_score(df):\n",
    "    \"\"\"\n",
    "    Sort the dataframe by total score in descending order\n",
    "    IN: df, pd.DataFrame, dataframe containing total_score column\n",
    "    OUT: df_sorted, pd.DataFrame, sorted dataframe\n",
    "    \"\"\"\n",
    "    # Your_Code_Here\n",
    "    return df_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd3612f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    student_assessments_with_total_score = compute_total_score(student_assessments_xlsx.copy(), skill_columns)\n",
    "    student_assessments_with_total_score = sort_by_total_score(student_assessments_with_total_score)\n",
    "    display(student_assessments_with_total_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8bbf916",
   "metadata": {},
   "source": [
    "### Group Statistics by Section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e6e4d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_section_statistics(df, skill_columns):\n",
    "    \"\"\"\n",
    "    Group students by section and compute the mean, median, and standard deviation for each skill proficiency column\n",
    "    IN: df, pd.DataFrame, dataframe containing student assessments\n",
    "    IN: skill_columns, list of str, list of skill proficiency columns\n",
    "    OUT: section_stats, pd.DataFrame, dataframe with section statistics\n",
    "    \"\"\"\n",
    "    # Your_Code_Here\n",
    "    return section_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1837f82b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    section_statistics = get_section_statistics(student_assessments_with_total_score.copy(), skill_columns)\n",
    "    display(section_statistics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abfd6610",
   "metadata": {},
   "source": [
    "### Pivot Table by Role and Section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a158f03e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pivot_table(df):\n",
    "    \"\"\"\n",
    "    Create a pivot table where rows correspond to role, columns correspond to section numbers, and entries contain the average total_score\n",
    "    IN: df, pd.DataFrame, dataframe containing student assessments\n",
    "    OUT: pivot_table, pd.DataFrame, pivot table\n",
    "    \"\"\"\n",
    "    # set role as categorical with specified order\n",
    "    # Your_Code_Here\n",
    "\n",
    "    # generate pivot table\n",
    "    # Your_Code_Here\n",
    "    \n",
    "    return pivot_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2579640e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    pivot_table = create_pivot_table(student_assessments_with_total_score.copy())\n",
    "    display(pivot_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77276d9b",
   "metadata": {},
   "source": [
    "### Format Timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b5c7c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_timestamp(df):\n",
    "    \"\"\"\n",
    "    Convert timestamp values to the EST timezone instead of UTC\n",
    "    IN: df, pd.DataFrame, dataframe containing student assessments\n",
    "    OUT: df, pd.DataFrame, dataframe with formatted timestamp\n",
    "    \"\"\"\n",
    "    # Your_Code_Here\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "496ba52a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    student_assessments_formatted_timestamp = format_timestamp(student_assessments_with_total_score.copy())\n",
    "    display(student_assessments_formatted_timestamp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c219d689",
   "metadata": {},
   "source": [
    "### Normalize Skill Proficiency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "682b92c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_skills(df, skill_columns):\n",
    "    \"\"\"\n",
    "    For each proficiency column, apply z-score normalization\n",
    "    IN: df, pd.DataFrame, dataframe containing student assessments\n",
    "    IN: skill_columns, list of str, list of skill proficiency columns\n",
    "    OUT: df, pd.DataFrame, dataframe with normalized skills\n",
    "    \"\"\"\n",
    "    # Your_Code_Here\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5716eda6",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    student_assessments_normalized = normalize_skills(student_assessments_formatted_timestamp.copy(), skill_columns)\n",
    "    display(student_assessments_normalized)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc1b6996",
   "metadata": {},
   "source": [
    "### Handle Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc816c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_missing_values(df, skill_columns):\n",
    "    \"\"\"\n",
    "    Fill missing values in each skill proficiency column with the column mean\n",
    "    IN: df, pd.DataFrame, dataframe containing student assessments\n",
    "    OUT: df, pd.DataFrame, dataframe with missing values handled\n",
    "    \"\"\"\n",
    "    # Your_Code_Here\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d91ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    student_assessments_no_missing = handle_missing_values(student_assessments_normalized.copy(), skill_columns)\n",
    "    display(student_assessments_no_missing)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cf34755",
   "metadata": {},
   "source": [
    "### Remove Duplicate Records"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26db54ef",
   "metadata": {},
   "source": [
    "Note: Drop duplicates based on `ruid`. Keep the record with the highest `total_score`. If there is a tie, keep the one whose `timestamp` is latest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca0deec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_duplicates(df):\n",
    "    \"\"\"\n",
    "    Drop duplicates while keeping only the record with the highest total_score\n",
    "    IN: df, pd.DataFrame, dataframe containing student assessments\n",
    "    OUT: df, pd.DataFrame, dataframe with duplicates removed\n",
    "    \"\"\"\n",
    "    # sort by total_score descending, then by timestamp descending\n",
    "    # Your_Code_Here\n",
    "\n",
    "    # drop duplicates\n",
    "    # Your_Code_Here\n",
    "    \n",
    "    # sort back\n",
    "    # Your_Code_Here\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b4c57b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    student_assessments_no_duplicates = remove_duplicates(student_assessments_no_missing.copy())\n",
    "    display(student_assessments_no_duplicates)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "468338cd",
   "metadata": {},
   "source": [
    "### Resolve Swapped IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "291c3411",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_swapped_records(df):\n",
    "    \"\"\"\n",
    "    Identify records where students may have swapped netid and ruid\n",
    "    IN: df, pd.DataFrame, dataframe containing student assessments\n",
    "    OUT: swapped_df, pd.DataFrame, dataframe containing swapped records\n",
    "    \"\"\"\n",
    "    # calculate lengths\n",
    "    # Your_Code_Here\n",
    "\n",
    "    # find netid with exactly 18 characters and ruid length between 8 and 14\n",
    "    # Your_Code_Here\n",
    "    \n",
    "    return swapped_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d3aa0af",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    swapped_records = get_swapped_records(student_assessments_no_duplicates.copy())\n",
    "    display(swapped_records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35f7da7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def join_swapped_records(df_swapped, student_list_df):\n",
    "    \"\"\"\n",
    "    Join the swapped records with the student list to correct netid and ruid\n",
    "    IN: df_swapped, pd.DataFrame, dataframe containing swapped records\n",
    "    IN: student_list_df, pd.DataFrame, dataframe containing student list\n",
    "    OUT: joined_df, pd.DataFrame, dataframe with corrected netid and ruid\n",
    "    \"\"\"\n",
    "    # Your_Code_Here\n",
    "    return joined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f9aa63d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    joined_swapped = join_swapped_records(swapped_records.copy(), student_list_df)\n",
    "    display(joined_swapped)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cc36008",
   "metadata": {},
   "source": [
    "### DataFrame Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe4899a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    section_statistics.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c4f7df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    pivot_table.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f9275bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    student_assessments_no_duplicates.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f5754b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    joined_swapped.info()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
